{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "pip install tensorflow_addons"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tNub-g9OTBer",
    "outputId": "edf87fc4-6423-400b-be8c-c4d690561c3d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.17.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8g4N2Je3GxB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil as sh\n",
    "import random as rng\n",
    "import glob\n",
    "# import itertools\n",
    "\n",
    "import librosa as lb\n",
    "from librosa.display import specshow\n",
    "import IPython.display as ipd\n",
    "\n",
    "\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9emmQj03Rsx",
    "outputId": "bb6e3405-4019-4548-c6ce-3582ba1ac8c0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iICR-Ysk3GxE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#  --  Defining Variables  --  #\n",
    "\n",
    "max_ms = 4000\n",
    "\n",
    "batchs = 128\n",
    "epochs = 100\n",
    "\n",
    "ind_to_label = {\n",
    "    0 : 'angry',\n",
    "    1 : 'fear',\n",
    "    2 : 'happy',\n",
    "    3 : 'neutral',\n",
    "    4 : 'sad'\n",
    "}\n",
    "\n",
    "label_to_ind = { \n",
    "    lab: ind for ind, lab in ind_to_label.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRm58mWP3GxE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Data insights\n",
    "\n",
    "'''\n",
    "\n",
    "class aud_stats:\n",
    "    @staticmethod\n",
    "    def average_sr():\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "\n",
    "PREPROCESSING UTILS\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "class aud_util:\n",
    "    \n",
    "    @staticmethod\n",
    "    def loadaud(audio_file_path, sr=None, mono=False):                                 # load audio file, *mono argument (bool) can auto convert to mono, while default sr is converted to 22050*\n",
    "        return lb.load(audio_file_path, sr=sr, mono=mono)                              # returns (data, sr)       \n",
    "\n",
    "    @staticmethod\n",
    "    def pad_trunc(aud, sr, target_ms):                                                 # padding places shorter audio randomly within the time frame of the padded length\n",
    "        maxlen = (target_ms//1000)*sr\n",
    "        \n",
    "        if len(aud) == maxlen:\n",
    "            return aud, sr\n",
    "\n",
    "        elif len(aud) > maxlen:\n",
    "            return aud[:maxlen], sr\n",
    "\n",
    "        elif len(aud) < maxlen:\n",
    "            pad = maxlen - len(aud)\n",
    "            pad = np.zeros((pad))\n",
    "            return np.concatenate((aud, pad), 0), sr\n",
    "\n",
    "\n",
    "\n",
    "class aud_img:\n",
    "    @staticmethod\n",
    "    def melspec(data, sr):                                                             # returns 3 channels, deplicated from 1\n",
    "        spec = lb.feature.melspectrogram(data, sr=sr, power=1)                         # power = 1/2 changes amplitude_to_db or power_to_db\n",
    "        spec = lb.amplitude_to_db(spec, ref=np.min)\n",
    "        spec = np.expand_dims(spec, axis=2)\n",
    "        return np.stack((spec,)*3, axis=2).squeeze()\n",
    "\n",
    "    @staticmethod\n",
    "    def mfcc(data, sr):                                                                # returns 3 channels, deplicated from 1\n",
    "        mfcc_ = lb.feature.mfcc(data, sr)\n",
    "        #mfcc_ = sk.preprocessing.scale(mfcc_, axis=1)\n",
    "        mfcc_ = np.expand_dims(mfcc_, axis=2)\n",
    "        return np.stack((mfcc_,)*3, axis=2).squeeze()\n",
    "\n",
    "    @staticmethod\n",
    "    def display_audio_img(spec, sr , mfcc=False):\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "        if mfcc:\n",
    "            specshow(spec, sr=sr, x_axis='time')\n",
    "        else:\n",
    "            img = specshow(spec, x_axis='time', y_axis='mel', sr=sr, fmax=8000, ax=ax)\n",
    "            fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "\n",
    "\n",
    "class rav_prep:\n",
    "    '''\n",
    "    01 = neutral, \n",
    "    02 = calm,  -\n",
    "    03 = happy, \n",
    "    04 = sad, \n",
    "    05 = angry, \n",
    "    06 = fearful, \n",
    "    07 = disgust,  -\n",
    "    08 = surprised -\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def correct_data_type(path):\n",
    "        if (path.split('/')[-1].split('-')[0] == '03') and (path.split('/')[-1].split('-')[1] == '01') and (path.split('/')[-1].split('-')[2] in ['01', '03', '04', '05', '06']):\n",
    "          return True\n",
    "        else:\n",
    "          return False\n",
    "    \n",
    "    @staticmethod\n",
    "    def filter(path):\n",
    "      counter = 0\n",
    "      for i in glob.glob(path):\n",
    "        if rav_prep.correct_data_type(i):\n",
    "          continue\n",
    "        elif rav_prep.correct_data_type(i) != True:\n",
    "          sh.move(i, '/content/drive/MyDrive/NLP/RAVDESS_altogether/modified_data/A_removed_files')\n",
    "          counter += 1\n",
    "          continue\n",
    "      print(f'removed {counter} files')\n",
    "\n",
    "    @staticmethod\n",
    "    def move_ravdess_colab(path):                                               # colab google drive paths\n",
    "      for i in glob.glob(path):\n",
    "        if i.split('/')[-1].split('-')[2] == '05':\n",
    "          sh.copy(i, '/content/drive/MyDrive/NLP/RAVDESS_altogether/modified_data/angry')\n",
    "        \n",
    "        elif i.split('/')[-1].split('-')[2] == '06':\n",
    "          sh.copy(i, '/content/drive/MyDrive/NLP/RAVDESS_altogether/modified_data/fear')\n",
    "\n",
    "        elif i.split('/')[-1].split('-')[2] == '03':\n",
    "          sh.copy(i, '/content/drive/MyDrive/NLP/RAVDESS_altogether/modified_data/happy')\n",
    "\n",
    "        elif i.split('/')[-1].split('-')[2] == '01':\n",
    "          sh.copy(i, '/content/drive/MyDrive/NLP/RAVDESS_altogether/modified_data/neutral')\n",
    "\n",
    "        elif i.split('/')[-1].split('-')[2] == '04':\n",
    "          sh.copy(i, '/content/drive/MyDrive/NLP/RAVDESS_altogether/modified_data/sad')\n",
    "\n",
    "\n",
    "class ds_create:\n",
    "    \n",
    "    @staticmethod    \n",
    "    def label_from_bpath(bpath):                                                       # probably will not be used\n",
    "        return bpath.decode('utf-8').split('\\\\')[-2]\n",
    "\n",
    "    @staticmethod\n",
    "    def slices_for_onelabel(path, label):                                              \n",
    "        paths = glob.glob(path)\n",
    "\n",
    "        labels = [label_to_ind[label]]*len(paths)\n",
    "\n",
    "        return paths , labels\n",
    "\n",
    "    @staticmethod\n",
    "    def dfpremel(path):\n",
    "        data, sr = aud_util.loadaud(path, sr=16000, mono=True)\n",
    "        data, sr = aud_util.pad_trunc(data, sr, max_ms)                                \n",
    "        mel = aud_img.melspec(data, sr)\n",
    "        return mel\n",
    "    \n",
    "    @staticmethod\n",
    "    def dfpremfcc(path):\n",
    "        data, sr = aud_util.loadaud(path, sr=16000, mono=True)\n",
    "        data, sr = aud_util.pad_trunc(data, sr, max_ms)                                \n",
    "        mel = aud_img.mfcc(data, sr)\n",
    "        return mel\n",
    "\n"
   ],
   "metadata": {
    "id": "ITKWjwvvnZnk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "organising ravdess data \n",
    "Done once only, by the time you see this cell, it probably was already run, so you can ignore it \n",
    "as all the revdess files have already been organised into the sub-emotion folder in the google drive, in\n",
    "/content/drive/MyDrive/NLP/RAVDESS_altogether/modified_data\n",
    "\n",
    "'''\n",
    "\n",
    "rav_prep.filter('/content/drive/MyDrive/NLP/RAVDESS_altogether/modified_data/Altogether/*.wav')\n",
    "rav_prep.move_ravdess_colab('/content/drive/MyDrive/NLP/RAVDESS_altogether/modified_data/Altogether/*.wav')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uu-N6Za66BPG",
    "outputId": "9722e1d4-a127-4eea-d008-dacce07e20c5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "removed 576 files\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCQeMCrk3GxI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "BUILDING DATASET PIPELINE (only original training data included)\n",
    "\n",
    "'_o' means original data, excluding any extra data\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "angry_o, _0 =   ds_create.slices_for_onelabel(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/angry/*.wav', 'angry')\n",
    "fear_o, _1 =    ds_create.slices_for_onelabel(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/fear/*.wav', 'fear')\n",
    "happy_o, _2 =   ds_create.slices_for_onelabel(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/happy/*.wav', 'happy')\n",
    "neutral_o, _3 = ds_create.slices_for_onelabel(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/neutral/*.wav', 'neutral')\n",
    "sad_o, _4 =     ds_create.slices_for_onelabel(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/sad/*.wav', 'sad')\n",
    "\n",
    "slices = angry_o + fear_o + happy_o + neutral_o + sad_o\n",
    "labels = _0 + _1 + _2 + _3 + _4\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "BUILDING DATASET PIPELINE (both original data and ravdess)\n",
    "\n",
    "'_o' means original data, excluding any extra data\n",
    "\n",
    "'''\n",
    "\n",
    "angry_o, _0 =   ds_create.slices_for_onelabel(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/angry/*.wav', 'angry')\n",
    "fear_o, _1 =    ds_create.slices_for_onelabel(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/fear/*.wav', 'fear')\n",
    "happy_o, _2 =   ds_create.slices_for_onelabel(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/happy/*.wav', 'happy')\n",
    "neutral_o, _3 = ds_create.slices_for_onelabel(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/neutral/*.wav', 'neutral')\n",
    "sad_o, _4 =     ds_create.slices_for_onelabel(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/sad/*.wav', 'sad')\n",
    "\n",
    "angry_r, r_0 =   ds_create.slices_for_onelabel(r'/content/drive/MyDrive/NLP/RAVDESS_altogether/modified_data/angry/*.wav', 'angry')\n",
    "fear_r, r_1 =    ds_create.slices_for_onelabel(r'/content/drive/MyDrive/NLP/RAVDESS_altogether/modified_data/fear/*.wav', 'fear')\n",
    "happy_r, r_2 =   ds_create.slices_for_onelabel(r'/content/drive/MyDrive/NLP/RAVDESS_altogether/modified_data/happy/*.wav', 'happy')\n",
    "neutral_r, r_3 = ds_create.slices_for_onelabel(r'/content/drive/MyDrive/NLP/RAVDESS_altogether/modified_data/neutral/*.wav', 'neutral')\n",
    "sad_r, r_4 =     ds_create.slices_for_onelabel(r'/content/drive/MyDrive/NLP/RAVDESS_altogether/modified_data/sad/*.wav', 'sad')\n",
    "\n",
    "\n",
    "slices = angry_o + fear_o + happy_o + neutral_o + sad_o    +   angry_r + fear_r + happy_r + neutral_r + sad_r\n",
    "labels = _0 + _1 + _2 + _3 + _4   +   r_0 + r_1 + r_2 + r_3 + r_4\n",
    "\n"
   ],
   "metadata": {
    "id": "HM7Tux-YGMrp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HFG2j4pS3GxJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Dataframe style\n",
    "\n",
    "using tf.stack later lol\n",
    "'''\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['relative_audio_paths'] = slices\n",
    "df['int_labels'] = labels\n",
    "df['1hot_labels'] = list(to_categorical(labels))\n",
    "\n",
    "df['imgs_3c'] = list(map(ds_create.dfpremel, slices))\n",
    "\n",
    "\n",
    "df = sk.utils.shuffle(df)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "icL9-cYI3GxJ",
    "outputId": "a0486113-af97-4f25-fc93-47283bb1d432",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                relative_audio_paths  int_labels  \\\n",
       "0  /content/drive/MyDrive/NLP/RAVDESS_altogether/...           1   \n",
       "1  /content/drive/MyDrive/NLP/NLP Training Datase...           2   \n",
       "2  /content/drive/MyDrive/NLP/NLP Training Datase...           4   \n",
       "3  /content/drive/MyDrive/NLP/RAVDESS_altogether/...           1   \n",
       "4  /content/drive/MyDrive/NLP/NLP Training Datase...           4   \n",
       "\n",
       "                 1hot_labels  \\\n",
       "0  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "3  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "\n",
       "                                             imgs_3c  \n",
       "0  [[[37.347054, 37.347054, 37.347054], [37.34705...  \n",
       "1  [[[63.72838126616919, 63.72838126616919, 63.72...  \n",
       "2  [[[87.36988820126425, 87.36988820126425, 87.36...  \n",
       "3  [[[38.92079559238242, 38.92079559238242, 38.92...  \n",
       "4  [[[76.25816571916035, 76.25816571916035, 76.25...  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-687c041f-9e07-4fd0-857e-7872a1e0e9ee\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_audio_paths</th>\n",
       "      <th>int_labels</th>\n",
       "      <th>1hot_labels</th>\n",
       "      <th>imgs_3c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/content/drive/MyDrive/NLP/RAVDESS_altogether/...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[[[37.347054, 37.347054, 37.347054], [37.34705...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/content/drive/MyDrive/NLP/NLP Training Datase...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[[[63.72838126616919, 63.72838126616919, 63.72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/content/drive/MyDrive/NLP/NLP Training Datase...</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[[[87.36988820126425, 87.36988820126425, 87.36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/content/drive/MyDrive/NLP/RAVDESS_altogether/...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[[[38.92079559238242, 38.92079559238242, 38.92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/content/drive/MyDrive/NLP/NLP Training Datase...</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[[[76.25816571916035, 76.25816571916035, 76.25...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-687c041f-9e07-4fd0-857e-7872a1e0e9ee')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-687c041f-9e07-4fd0-857e-7872a1e0e9ee button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-687c041f-9e07-4fd0-857e-7872a1e0e9ee');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3hBgoy43GxK",
    "outputId": "5b7d2867-4b45-44db-8623-448775f1b09c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(128, 126, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "df.iloc[0,3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SW3giI733GxK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "ignore this cell\n",
    "\n",
    "'''\n",
    "# requires shuffling in tf.keras.Model.fit\n",
    "\n",
    "X = list(map(ds_create.path_to_mel, slices))\n",
    "\n",
    "Y = np.array(to_categorical(labels))\n",
    "X = np.array(X)\n",
    "\n",
    "\n",
    "#ds = ds.map(ds_create.preprocess_mel_eachlabel)\n",
    "ds = ds.map(ds_create.preprocess_mel_eachlabel)\n",
    "# ds = ds.cache()\n",
    "# ds = ds.batch(batchs)\n",
    "# ds = ds.prefetch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5TlqaMX-3GxL",
    "outputId": "90f95f00-d646-42fd-87e9-d890aef265bc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(128, 126, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "input_shape = df.iloc[0,3].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e6-Qzo5J3GxL",
    "outputId": "8b341ddc-7d97-4179-ce98-44274b867fe7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 126, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetv2-s (Functiona  (None, None, None, 1280)  20331360 \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 20480)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               5243136   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,608,037\n",
      "Trainable params: 25,454,165\n",
      "Non-trainable params: 153,872\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xin = Input(input_shape)\n",
    "\n",
    "prenet = tf.keras.applications.efficientnet_v2.EfficientNetV2S(weights='imagenet', include_top=False)#, input_shape=input_shape)\n",
    "x = prenet(xin)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='swish')(x)\n",
    "x = Dropout(0.65)(x)\n",
    "x = Dense(128, activation='swish')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "\n",
    "xout = Dense(5, activation='softmax')(x)\n",
    "\n",
    "own = Model(xin, xout)\n",
    "own.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['acc', tfa.metrics.F1Score(num_classes=5, average='weighted', threshold=0.5)])\n",
    "own.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQ7XBRJw3GxM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.1, verbose=1),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint(r'/content/drive/MyDrive/NLP/Zhihaos stuff/effinet v2s', monitor='val_loss', verbose=0, save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rcgEkPN23GxM",
    "outputId": "b18f9536-dfc0-4939-e20a-dae8e2cc8f6c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.5855 - acc: 0.3710 - f1_score: 0.2792INFO:tensorflow:Assets written to: /content/drive/MyDrive/NLP/Zhihaos stuff/effinet v2s/assets\n",
      "28/28 [==============================] - 130s 4s/step - loss: 1.5855 - acc: 0.3710 - f1_score: 0.2792 - val_loss: 1.1825 - val_acc: 0.5464 - val_f1_score: 0.3523 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 10s 367ms/step - loss: 1.0994 - acc: 0.5783 - f1_score: 0.5257 - val_loss: 1.1956 - val_acc: 0.6025 - val_f1_score: 0.5603 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8599 - acc: 0.6772 - f1_score: 0.6622INFO:tensorflow:Assets written to: /content/drive/MyDrive/NLP/Zhihaos stuff/effinet v2s/assets\n",
      "28/28 [==============================] - 107s 4s/step - loss: 0.8599 - acc: 0.6772 - f1_score: 0.6622 - val_loss: 0.7853 - val_acc: 0.7251 - val_f1_score: 0.7014 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 10s 368ms/step - loss: 0.8243 - acc: 0.7178 - f1_score: 0.6932 - val_loss: 0.8167 - val_acc: 0.6930 - val_f1_score: 0.6355 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 10s 367ms/step - loss: 0.7875 - acc: 0.7210 - f1_score: 0.6983 - val_loss: 0.8913 - val_acc: 0.6930 - val_f1_score: 0.6783 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7460 - acc: 0.7267 - f1_score: 0.7081INFO:tensorflow:Assets written to: /content/drive/MyDrive/NLP/Zhihaos stuff/effinet v2s/assets\n",
      "28/28 [==============================] - 106s 4s/step - loss: 0.7460 - acc: 0.7267 - f1_score: 0.7081 - val_loss: 0.7052 - val_acc: 0.7549 - val_f1_score: 0.7358 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6826 - acc: 0.7557 - f1_score: 0.7381INFO:tensorflow:Assets written to: /content/drive/MyDrive/NLP/Zhihaos stuff/effinet v2s/assets\n",
      "28/28 [==============================] - 108s 4s/step - loss: 0.6826 - acc: 0.7557 - f1_score: 0.7381 - val_loss: 0.6920 - val_acc: 0.7881 - val_f1_score: 0.7867 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 10s 369ms/step - loss: 0.5584 - acc: 0.7983 - f1_score: 0.7876 - val_loss: 1.1029 - val_acc: 0.7537 - val_f1_score: 0.7646 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 10s 371ms/step - loss: 0.8040 - acc: 0.7279 - f1_score: 0.6961 - val_loss: 0.7463 - val_acc: 0.7549 - val_f1_score: 0.7442 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6655 - acc: 0.7892 - f1_score: 0.7610INFO:tensorflow:Assets written to: /content/drive/MyDrive/NLP/Zhihaos stuff/effinet v2s/assets\n",
      "28/28 [==============================] - 107s 4s/step - loss: 0.6655 - acc: 0.7892 - f1_score: 0.7610 - val_loss: 0.6865 - val_acc: 0.7572 - val_f1_score: 0.7474 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4929 - acc: 0.8330 - f1_score: 0.8225INFO:tensorflow:Assets written to: /content/drive/MyDrive/NLP/Zhihaos stuff/effinet v2s/assets\n",
      "28/28 [==============================] - 107s 4s/step - loss: 0.4929 - acc: 0.8330 - f1_score: 0.8225 - val_loss: 0.6242 - val_acc: 0.7824 - val_f1_score: 0.7908 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 10s 368ms/step - loss: 0.3248 - acc: 0.9003 - f1_score: 0.8914 - val_loss: 0.6752 - val_acc: 0.8110 - val_f1_score: 0.8123 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 10s 368ms/step - loss: 0.3744 - acc: 0.8954 - f1_score: 0.8842 - val_loss: 0.7363 - val_acc: 0.7423 - val_f1_score: 0.7515 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3681 - acc: 0.8963 - f1_score: 0.8858INFO:tensorflow:Assets written to: /content/drive/MyDrive/NLP/Zhihaos stuff/effinet v2s/assets\n",
      "28/28 [==============================] - 109s 4s/step - loss: 0.3681 - acc: 0.8963 - f1_score: 0.8858 - val_loss: 0.5675 - val_acc: 0.8259 - val_f1_score: 0.8245 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2736 - acc: 0.9161 - f1_score: 0.9139INFO:tensorflow:Assets written to: /content/drive/MyDrive/NLP/Zhihaos stuff/effinet v2s/assets\n",
      "28/28 [==============================] - 107s 4s/step - loss: 0.2736 - acc: 0.9161 - f1_score: 0.9139 - val_loss: 0.5310 - val_acc: 0.8477 - val_f1_score: 0.8411 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 10s 369ms/step - loss: 0.2067 - acc: 0.9453 - f1_score: 0.9447 - val_loss: 0.8518 - val_acc: 0.8076 - val_f1_score: 0.8057 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 10s 368ms/step - loss: 0.4142 - acc: 0.8702 - f1_score: 0.8680 - val_loss: 0.6478 - val_acc: 0.8156 - val_f1_score: 0.8136 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3019 - acc: 0.9161 - f1_score: 0.9142\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "28/28 [==============================] - 10s 369ms/step - loss: 0.3019 - acc: 0.9161 - f1_score: 0.9142 - val_loss: 0.5416 - val_acc: 0.8442 - val_f1_score: 0.8466 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.1620 - acc: 0.9530 - f1_score: 0.9514INFO:tensorflow:Assets written to: /content/drive/MyDrive/NLP/Zhihaos stuff/effinet v2s/assets\n",
      "28/28 [==============================] - 108s 4s/step - loss: 0.1620 - acc: 0.9530 - f1_score: 0.9514 - val_loss: 0.4487 - val_acc: 0.8660 - val_f1_score: 0.8717 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.0972 - acc: 0.9765 - f1_score: 0.9745INFO:tensorflow:Assets written to: /content/drive/MyDrive/NLP/Zhihaos stuff/effinet v2s/assets\n",
      "28/28 [==============================] - 108s 4s/step - loss: 0.0972 - acc: 0.9765 - f1_score: 0.9745 - val_loss: 0.4420 - val_acc: 0.8774 - val_f1_score: 0.8808 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 10s 369ms/step - loss: 0.0753 - acc: 0.9791 - f1_score: 0.9767 - val_loss: 0.4698 - val_acc: 0.8843 - val_f1_score: 0.8888 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 10s 368ms/step - loss: 0.0645 - acc: 0.9814 - f1_score: 0.9802 - val_loss: 0.4619 - val_acc: 0.8809 - val_f1_score: 0.8829 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.0494 - acc: 0.9860 - f1_score: 0.9851\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "28/28 [==============================] - 10s 367ms/step - loss: 0.0494 - acc: 0.9860 - f1_score: 0.9851 - val_loss: 0.4914 - val_acc: 0.8774 - val_f1_score: 0.8828 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 10s 368ms/step - loss: 0.0459 - acc: 0.9865 - f1_score: 0.9864 - val_loss: 0.4944 - val_acc: 0.8797 - val_f1_score: 0.8841 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 10s 368ms/step - loss: 0.0534 - acc: 0.9891 - f1_score: 0.9883 - val_loss: 0.5092 - val_acc: 0.8809 - val_f1_score: 0.8827 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.0512 - acc: 0.9877 - f1_score: 0.9831\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "28/28 [==============================] - 10s 368ms/step - loss: 0.0512 - acc: 0.9877 - f1_score: 0.9831 - val_loss: 0.4986 - val_acc: 0.8786 - val_f1_score: 0.8843 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 11s 377ms/step - loss: 0.0442 - acc: 0.9888 - f1_score: 0.9868 - val_loss: 0.4999 - val_acc: 0.8832 - val_f1_score: 0.8839 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "history = own.fit(\n",
    "    x=tf.stack(df['imgs_3c']),\n",
    "    y=tf.stack(df['1hot_labels']),\n",
    "    batch_size=batchs,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tFlMT1x3GxM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tst = ds_create.dfpremel(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/fear/00530e07e3.wav')\n",
    "tst = ds_create.dup_channel(tst)\n",
    "tst = np.expand_dims(tst, axis=0)                                             # EXPAND DIMS OF FIRST DIMENSION ARGHHHHHH\n",
    "pred = own.predict(tst)\n",
    "pred = np.argmax(pred)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDMxvMdP3GxN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Generating the qualifying csv file\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "class test_gen:\n",
    "    @staticmethod\n",
    "    def path_gen(path):                                              #for zhihao's local pc\n",
    "        paths = os.listdir(path)\n",
    "        paths = list(map(lambda x : 'DATA_NLP_TIL\\\\.qualifying_test\\\\'+x , paths))\n",
    "\n",
    "        return paths \n",
    "\n",
    "    @staticmethod\n",
    "    def path_gen_colab(path):                                              #for colab, zhihaos\n",
    "        paths = os.listdir(path)\n",
    "        paths = list(map(lambda x : '/content/drive/MyDrive/NLP/NLP Interim Dataset/NLP/'+x , paths))\n",
    "\n",
    "        return paths \n",
    "\n",
    "    @staticmethod\n",
    "    def path_to_mel(path):\n",
    "        ccc = ds_create.dfpremel(path)\n",
    "        return ccc\n",
    "    \n",
    "    @staticmethod\n",
    "    def path_to_mfcc(path):\n",
    "        ccc = ds_create.dfpremfcc(path)\n",
    "        return ccc\n",
    "\n",
    "    @staticmethod\n",
    "    def int_to_label(int):\n",
    "        return ind_to_label[int]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "q_df = pd.DataFrame()\n",
    "paths = sorted(glob.glob(r'/content/drive/MyDrive/NLP/NLP Interim Dataset/NLP/*.wav'))\n",
    "q_data = list(map(test_gen.path_to_mel, paths))\n",
    "\n",
    "q_data = tf.stack(q_data)\n",
    "\n",
    "preds = own.predict(q_data)\n",
    "preds = np.argmax(preds, axis=1)"
   ],
   "metadata": {
    "id": "2QJXAxyVMp7y",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "q_df['paths'] = sorted(os.listdir(r'/content/drive/MyDrive/NLP/NLP Interim Dataset/NLP/'))\n",
    "q_df['labels'] = list(map(\n",
    "    test_gen.int_to_label,\n",
    "    list(preds)\n",
    "))"
   ],
   "metadata": {
    "id": "HMiSafBkOTfp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "q_df.head()"
   ],
   "metadata": {
    "id": "rbFehkxqUGss",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "outputId": "2d519aea-2bd3-4d53-c5c0-c9474216aab3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            paths labels\n",
       "0  00ae09ba94.wav  angry\n",
       "1  00f2a00f1f.wav  angry\n",
       "2  012822b908.wav   fear\n",
       "3  0144091c26.wav    sad\n",
       "4  0145cb0279.wav    sad"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-039a061f-1554-4ebc-8e2c-d18270b248a3\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paths</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00ae09ba94.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00f2a00f1f.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>012822b908.wav</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0144091c26.wav</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0145cb0279.wav</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-039a061f-1554-4ebc-8e2c-d18270b248a3')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-039a061f-1554-4ebc-8e2c-d18270b248a3 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-039a061f-1554-4ebc-8e2c-d18270b248a3');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "q_df.to_csv(r'/content/drive/MyDrive/NLP/Zhihao nlp preds/qualifiers4.csv', header=False, index=False)"
   ],
   "metadata": {
    "id": "kcxfIZE2UlkK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38c7ce74dd526bc9e84fd0682f6c1ac8fcd6c4cb0e87d36fcf4e0e214217cc07"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "colab": {
   "name": "zhihao_nlp_2022TIL_(ignore othernotebook).ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}