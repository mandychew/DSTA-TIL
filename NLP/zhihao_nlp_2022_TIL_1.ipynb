{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tNub-g9OTBer",
    "outputId": "2cdf46e5-b5c0-44b4-f14f-a1a86c45f736",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting tensorflow_addons\n",
      "  Downloading tensorflow_addons-0.17.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.1 MB 9.9 MB/s \n",
      "\u001B[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (21.3)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
      "Installing collected packages: tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.17.0\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8g4N2Je3GxB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random as rng\n",
    "import glob\n",
    "# import itertools\n",
    "\n",
    "import librosa as lb\n",
    "from librosa.display import specshow\n",
    "import IPython.display as ipd\n",
    "\n",
    "\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9emmQj03Rsx",
    "outputId": "e0645cad-5ad7-4dc5-c9f4-f72f208b13bd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iICR-Ysk3GxE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#  --  Defining Variables  --  #\n",
    "\n",
    "max_ms = 4000\n",
    "\n",
    "batchs = 256\n",
    "epochs = 100\n",
    "\n",
    "ind_to_label = {\n",
    "    0 : 'angry',\n",
    "    1 : 'fear',\n",
    "    2 : 'happy',\n",
    "    3 : 'neutral',\n",
    "    4 : 'sad'\n",
    "}\n",
    "\n",
    "label_to_ind = { \n",
    "    lab: ind for ind, lab in ind_to_label.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRm58mWP3GxE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Data insights\n",
    "\n",
    "'''\n",
    "\n",
    "class aud_stats:\n",
    "    @staticmethod\n",
    "    def average_sr():\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6BDl7XE3GxF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "PREPROCESSING UTILS\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "class aud_util:\n",
    "    \n",
    "    @staticmethod\n",
    "    def loadaud(audio_file_path, sr=None, mono=False):                                 # load audio file, *mono argument (bool) can auto convert to mono, while default sr is converted to 22050*\n",
    "        return lb.load(audio_file_path, sr=sr, mono=mono)                              # returns (data, sr)       \n",
    "\n",
    "    @staticmethod\n",
    "    def tf_loadaud(audio_file_path, sr=-1, mono=False):                                # only works with 16-bit audio\n",
    "        file = tf.io.read_file(audio_file_path)\n",
    "        \n",
    "        if mono:\n",
    "            dc = 1\n",
    "        elif not mono:\n",
    "            dc = -1\n",
    "        \n",
    "        return tf.audio.decode_wav(file, desired_channels=dc, desired_samples=sr)\n",
    "    \n",
    "    @staticmethod\n",
    "    def mono_channel_withsr(audio_data_with_sr):\n",
    "        return lb.to_mono(audio_data_with_sr[0]), audio_data_with_sr[1]\n",
    "\n",
    "    @staticmethod\n",
    "    def resample_withsr(data, in_sr, new_sr=22050):\n",
    "        if in_sr == new_sr:\n",
    "            return data\n",
    "        else:\n",
    "            return lb.resample(data, orig_sr=sr, new_sr=new_sr)\n",
    "    \n",
    "    @staticmethod\n",
    "    def pad_trunc(aud, sr, target_ms):                                                 # padding places shorter audio randomly within the time frame of the padded length\n",
    "        maxlen = (target_ms//1000)*sr\n",
    "        \n",
    "        if len(aud) == maxlen:\n",
    "            return aud, sr\n",
    "\n",
    "        elif len(aud) > maxlen:\n",
    "            return aud[:maxlen], sr\n",
    "\n",
    "        elif len(aud) < maxlen:\n",
    "            \n",
    "            #     random padding positions\n",
    "            pad = maxlen - len(aud)\n",
    "            pad = np.zeros((pad))\n",
    "\n",
    "            # pad_begin_len = rng.randint(0, maxlen - len(aud))\n",
    "            # pad_end_len = maxlen - len(aud) - pad_begin_len\n",
    "\n",
    "            #     actaual padding\n",
    "            # pad_begin = np.zeros((pad_begin_len))\n",
    "            # pad_end = np.zeros((pad_end_len))\n",
    "\n",
    "            return np.concatenate((aud, pad), 0), sr\n",
    "\n",
    "\n",
    "\n",
    "class aud_img:\n",
    "    @staticmethod\n",
    "    def melspec(data, sr):\n",
    "        spec = lb.feature.melspectrogram(data, sr=sr, power=1)                         # power = 1/2 changes amplitude_to_db or power_to_db\n",
    "        spec = lb.amplitude_to_db(spec, ref=np.min)\n",
    "        return spec\n",
    "\n",
    "    @staticmethod\n",
    "    def mfcc(data, sr):\n",
    "        mfcc_ = lb.feature.mfcc(data, sr)\n",
    "        #mfcc_ = sk.preprocessing.scale(mfcc_, axis=1)\n",
    "        return mfcc_\n",
    "\n",
    "    @staticmethod\n",
    "    def display_audio_img(spec, sr , mfcc=False):\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "        if mfcc:\n",
    "            specshow(spec, sr=sr, x_axis='time')\n",
    "        else:\n",
    "            img = specshow(spec, x_axis='time', y_axis='mel', sr=sr, fmax=8000, ax=ax)\n",
    "            fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "\n",
    "\n",
    "\n",
    "class ds_create:\n",
    "    \n",
    "    @staticmethod    \n",
    "    def label_from_bpath(bpath):                                                       # probably will not be used\n",
    "        return bpath.decode('utf-8').split('\\\\')[-2]\n",
    "\n",
    "    @staticmethod\n",
    "    #depreciated\n",
    "    def one_label_dataset(path, label):                                                # path taken in must be raw\n",
    "        return tf.data.Dataset.zip((\n",
    "            tf.data.Dataset.list_files(path),\n",
    "            tf.data.Dataset.from_tensor_slices(tf.constant(value=label_to_ind[label], dtype=tf.dtypes.int32 ,shape=len(tf.data.Dataset.list_files(path))))\n",
    "        ))\n",
    "\n",
    "    @staticmethod\n",
    "    def slices_for_onelabel(path, label):                                              #for zhihao's local pc\n",
    "        paths = os.listdir(path)\n",
    "        paths = list(map(lambda x : 'DATA_NLP_TIL\\\\'+label+'\\\\'+x , paths))\n",
    "\n",
    "        labels = [label_to_ind[label]]*len(paths)\n",
    "\n",
    "        return paths , labels\n",
    "\n",
    "    @staticmethod\n",
    "    def slices_for_onelabel_colab(path, label):                              #for use in google drive, path looks like: /content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/sad/*.wav\n",
    "        paths = os.listdir(path)\n",
    "        paths = list(map(lambda x : '/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/'+label+'/'+x , paths))\n",
    "\n",
    "        labels = [label_to_ind[label]]*len(paths)\n",
    "\n",
    "        return paths , labels\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocess_mel_eachlabel(file_path, label):                          \n",
    "        \n",
    "        data, sr = aud_util.loadaud(file_path, sr=16000, mono=True)\n",
    "        data, sr = aud_util.pad_trunc(data, sr, max_ms)                                \n",
    "        mel = aud_img.melspec(data, sr)\n",
    "        mel = tf.expand_dims(mel, axis=2)\n",
    "        \n",
    "        return mel, label\n",
    "\n",
    "    @staticmethod\n",
    "    def path_to_mel(path):                                                              # temporary work around\n",
    "        \n",
    "        data, sr = aud_util.loadaud(path, sr=16000, mono=True)\n",
    "        data, sr = aud_util.pad_trunc(data, sr, max_ms)                                \n",
    "        mel = aud_img.melspec(data, sr)\n",
    "        mel = tf.expand_dims(mel, axis=2)\n",
    "\n",
    "        return mel\n",
    "\n",
    "    @staticmethod\n",
    "    def dfpremel(path):\n",
    "        data, sr = aud_util.loadaud(path, sr=16000, mono=True)\n",
    "        data, sr = aud_util.pad_trunc(data, sr, max_ms)                                \n",
    "        mel = aud_img.melspec(data, sr)\n",
    "        mel = np.expand_dims(mel, axis=2)\n",
    "\n",
    "        return mel\n",
    "    \n",
    "    @staticmethod\n",
    "    def dfpremfcc(path):\n",
    "        data, sr = aud_util.loadaud(path, sr=16000, mono=True)\n",
    "        data, sr = aud_util.pad_trunc(data, sr, max_ms)                                \n",
    "        mel = aud_img.mfcc(data, sr)\n",
    "        mel = np.expand_dims(mel, axis=2)\n",
    "\n",
    "        return mel\n",
    "\n",
    "    @staticmethod\n",
    "    def dup_channel(img):\n",
    "        return np.stack((img,)*3, axis=2).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCQeMCrk3GxI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "BUILDING DATASET PIPELINE (zhihao local machine)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# for zhihaos local machine\n",
    "angry, _0= ds_create.slices_for_onelabel(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/angry', 'angry')\n",
    "fear, _1 = ds_create.slices_for_onelabel(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/fear', 'fear')\n",
    "happy, _2 = ds_create.slices_for_onelabel(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/happy', 'happy')\n",
    "neutral, _3 = ds_create.slices_for_onelabel(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/neutral', 'neutral')\n",
    "sad, _4 = ds_create.slices_for_onelabel(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/sad', 'sad')\n",
    "\n",
    "slices = angry + fear + happy + neutral + sad\n",
    "labels = _0 + _1 + _2 + _3 + _4\n",
    "\n",
    "# ds = tf.data.Dataset.zip((\n",
    "#     tf.data.Dataset.list_files(slices, shuffle=False),\n",
    "#     tf.data.Dataset.from_tensor_slices(labels)\n",
    "# ))\n",
    "\n",
    "# ds = ds.shuffle(len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VFyNpWu6OdN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "BUILDING DATASET PIPELINE (colab)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# for zhihaos local machine\n",
    "\n",
    "angry, _0= ds_create.slices_for_onelabel_colab(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/angry', 'angry')\n",
    "fear, _1 = ds_create.slices_for_onelabel_colab(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/fear', 'fear')\n",
    "happy, _2 = ds_create.slices_for_onelabel_colab(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/happy', 'happy')\n",
    "neutral, _3 = ds_create.slices_for_onelabel_colab(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/neutral', 'neutral')\n",
    "sad, _4 = ds_create.slices_for_onelabel_colab(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/sad', 'sad')\n",
    "\n",
    "slices = angry + fear + happy + neutral + sad\n",
    "labels = _0 + _1 + _2 + _3 + _4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HFG2j4pS3GxJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Dataframe style\n",
    "\n",
    "using tf.stack later lol\n",
    "'''\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['relative_audio_paths'] = slices\n",
    "df['int_labels'] = labels\n",
    "df['1hot_labels'] = list(to_categorical(labels))\n",
    "\n",
    "df['imgs_1c'] = list(map(ds_create.dfpremel, slices))\n",
    "df['imgs_3c'] = df['imgs_1c'].map(ds_create.dup_channel)\n",
    "\n",
    "\n",
    "df = sk.utils.shuffle(df)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "icL9-cYI3GxJ",
    "outputId": "c73c4202-8226-4732-a0f1-abddbbc05342",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5b9a464d-3aa6-4377-b724-7bc1261b67a7\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_audio_paths</th>\n",
       "      <th>int_labels</th>\n",
       "      <th>1hot_labels</th>\n",
       "      <th>imgs_1c</th>\n",
       "      <th>imgs_3c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/content/drive/MyDrive/NLP/NLP Training Datase...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[[[-584.6054259957538], [-496.12201677296343],...</td>\n",
       "      <td>[[[-584.6054259957538, -584.6054259957538, -58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/content/drive/MyDrive/NLP/NLP Training Datase...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[[[-419.7661999396332], [-358.3028907341822], ...</td>\n",
       "      <td>[[[-419.7661999396332, -419.7661999396332, -41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/content/drive/MyDrive/NLP/NLP Training Datase...</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[[[-396.3697971229703], [-394.82210978193507],...</td>\n",
       "      <td>[[[-396.3697971229703, -396.3697971229703, -39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/content/drive/MyDrive/NLP/NLP Training Datase...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[[[-356.7272377958902], [-333.5591633403735], ...</td>\n",
       "      <td>[[[-356.7272377958902, -356.7272377958902, -35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/content/drive/MyDrive/NLP/NLP Training Datase...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[[[-532.5982656356001], [-513.5887220733171], ...</td>\n",
       "      <td>[[[-532.5982656356001, -532.5982656356001, -53...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b9a464d-3aa6-4377-b724-7bc1261b67a7')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-5b9a464d-3aa6-4377-b724-7bc1261b67a7 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-5b9a464d-3aa6-4377-b724-7bc1261b67a7');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                relative_audio_paths  int_labels  \\\n",
       "0  /content/drive/MyDrive/NLP/NLP Training Datase...           0   \n",
       "1  /content/drive/MyDrive/NLP/NLP Training Datase...           2   \n",
       "2  /content/drive/MyDrive/NLP/NLP Training Datase...           4   \n",
       "3  /content/drive/MyDrive/NLP/NLP Training Datase...           0   \n",
       "4  /content/drive/MyDrive/NLP/NLP Training Datase...           2   \n",
       "\n",
       "                 1hot_labels  \\\n",
       "0  [1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "3  [1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "4  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "\n",
       "                                             imgs_1c  \\\n",
       "0  [[[-584.6054259957538], [-496.12201677296343],...   \n",
       "1  [[[-419.7661999396332], [-358.3028907341822], ...   \n",
       "2  [[[-396.3697971229703], [-394.82210978193507],...   \n",
       "3  [[[-356.7272377958902], [-333.5591633403735], ...   \n",
       "4  [[[-532.5982656356001], [-513.5887220733171], ...   \n",
       "\n",
       "                                             imgs_3c  \n",
       "0  [[[-584.6054259957538, -584.6054259957538, -58...  \n",
       "1  [[[-419.7661999396332, -419.7661999396332, -41...  \n",
       "2  [[[-396.3697971229703, -396.3697971229703, -39...  \n",
       "3  [[[-356.7272377958902, -356.7272377958902, -35...  \n",
       "4  [[[-532.5982656356001, -532.5982656356001, -53...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3hBgoy43GxK",
    "outputId": "fa9f87f6-1641-42f8-b2be-98e5180a2567",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 126, 3)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SW3giI733GxK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# '''\n",
    "# Temporary work around for below error\n",
    "\n",
    "# '''\n",
    "# # requires shuffling in tf.keras.Model.fit\n",
    "\n",
    "# X = list(map(ds_create.path_to_mel, slices))\n",
    "\n",
    "# Y = np.array(to_categorical(labels))\n",
    "# X = np.array(X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# '''\n",
    "# TASKS: MAYBE TRY LOADING THINGS INTO A DATAFRAME FOR THIS CRUDE METHOD to make things clearer....?\n",
    "\n",
    "# '''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-D_QXSD3GxL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# '''\n",
    "# Supposedly proper mapping that keeps throwing errors\n",
    "\n",
    "# '''\n",
    "# #ds = ds.map(ds_create.preprocess_mel_eachlabel)\n",
    "# ds = ds.map(ds_create.preprocess_mel_eachlabel)\n",
    "# # ds = ds.cache()\n",
    "# # ds = ds.batch(batchs)\n",
    "# # ds = ds.prefetch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5TlqaMX-3GxL",
    "outputId": "1ccbc25b-53ef-4e08-c5fe-3a0c17f3f042",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 126, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = df.iloc[0,4].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "e6-Qzo5J3GxL",
    "outputId": "2ff841fc-7ceb-4960-bb58-33efd0ecdc3b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-41-274db28ffd5b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mxin\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mInput\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mprenet\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapplications\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mefficientnet_v2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEfficientNetV2s\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweights\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'imagenet'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minclude_top\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;31m#, input_shape=input_shape)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprenet\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mxin\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'keras.api._v2.keras.applications.efficientnet_v2' has no attribute 'EfficientNetV2s'"
     ]
    }
   ],
   "source": [
    "xin = Input(input_shape)\n",
    "\n",
    "prenet = tf.keras.applications.efficientnet_v2.EfficientNetV2s(weights='imagenet', include_top=False)#, input_shape=input_shape)\n",
    "x = prenet(xin)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='swish')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "# x = Dense(128, activation='swish')(x)\n",
    "# x = Dropout(0.75)(x)\n",
    "\n",
    "\n",
    "xout = Dense(5, activation='softmax')(x)\n",
    "\n",
    "own = Model(xin, xout)\n",
    "own.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['acc', tfa.metrics.F1Score(num_classes=5, average='weighted', threshold=0.5)])\n",
    "own.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQ7XBRJw3GxM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.1, verbose=1),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint(r'/content/drive/MyDrive/NLP/Zhihaos stuff/effinet v2s', monitor='val_loss', verbose=0, save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rcgEkPN23GxM",
    "outputId": "02a8d4ad-2fd4-47dc-9d14-22d2af6c3c3f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0664 - acc: 0.9832 - f1_score: 0.9828INFO:tensorflow:Assets written to: /content/drive/MyDrive/NLP/Zhihaos stuff/effinet v2s/assets\n",
      "11/11 [==============================] - 196s 20s/step - loss: 0.0664 - acc: 0.9832 - f1_score: 0.9828 - val_loss: 0.8465 - val_acc: 0.7543 - val_f1_score: 0.7505 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0606 - acc: 0.9850 - f1_score: 0.9852INFO:tensorflow:Assets written to: /content/drive/MyDrive/NLP/Zhihaos stuff/effinet v2s/assets\n",
      "11/11 [==============================] - 167s 17s/step - loss: 0.0606 - acc: 0.9850 - f1_score: 0.9852 - val_loss: 0.8420 - val_acc: 0.7600 - val_f1_score: 0.7585 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 5s 420ms/step - loss: 0.0548 - acc: 0.9861 - f1_score: 0.9871 - val_loss: 0.8496 - val_acc: 0.7586 - val_f1_score: 0.7526 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 5s 421ms/step - loss: 0.0465 - acc: 0.9914 - f1_score: 0.9916 - val_loss: 0.8583 - val_acc: 0.7543 - val_f1_score: 0.7534 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0472 - acc: 0.9889 - f1_score: 0.9894\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "11/11 [==============================] - 5s 421ms/step - loss: 0.0472 - acc: 0.9889 - f1_score: 0.9894 - val_loss: 0.8842 - val_acc: 0.7500 - val_f1_score: 0.7528 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 5s 423ms/step - loss: 0.0438 - acc: 0.9889 - f1_score: 0.9901 - val_loss: 0.8838 - val_acc: 0.7529 - val_f1_score: 0.7530 - lr: 1.0000e-06\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 5s 450ms/step - loss: 0.0395 - acc: 0.9936 - f1_score: 0.9921 - val_loss: 0.8808 - val_acc: 0.7543 - val_f1_score: 0.7524 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "history = own.fit(\n",
    "    x=tf.stack(df['imgs_3c']),\n",
    "    y=tf.stack(df['1hot_labels']),\n",
    "    batch_size=batchs,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tFlMT1x3GxM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tst = ds_create.dfpremel(r'/content/drive/MyDrive/NLP/NLP Training Dataset/ASR Training Dataset/fear/00530e07e3.wav')\n",
    "tst = ds_create.dup_channel(tst)\n",
    "tst = np.expand_dims(tst, axis=0)                                             # EXPAND DIMS OF FIRST DIMENSION ARGHHHHHH\n",
    "pred = own.predict(tst)\n",
    "pred = np.argmax(pred)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDMxvMdP3GxN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Generating the qualifying csv file\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "class test_gen:\n",
    "    @staticmethod\n",
    "    def path_gen(path):                                              #for zhihao's local pc\n",
    "        paths = os.listdir(path)\n",
    "        paths = list(map(lambda x : 'DATA_NLP_TIL\\\\.qualifying_test\\\\'+x , paths))\n",
    "\n",
    "        return paths \n",
    "\n",
    "    @staticmethod\n",
    "    def path_gen_colab(path):                                              #for colab, zhihaos\n",
    "        paths = os.listdir(path)\n",
    "        paths = list(map(lambda x : '/content/drive/MyDrive/NLP/NLP Interim Dataset/NLP/'+x , paths))\n",
    "\n",
    "        return paths \n",
    "\n",
    "    @staticmethod\n",
    "    def path_to_mel(path):\n",
    "        c = ds_create.dfpremel(path)\n",
    "        ccc = ds_create.dup_channel(c)\n",
    "        return ccc\n",
    "    \n",
    "    @staticmethod\n",
    "    def path_to_mfcc(path):\n",
    "        c = ds_create.dfpremfcc(path)\n",
    "        ccc = ds_create.dup_channel(c)\n",
    "        return ccc\n",
    "\n",
    "    @staticmethod\n",
    "    def int_to_label(int):\n",
    "        return ind_to_label[int]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QJXAxyVMp7y",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "q_df = pd.DataFrame()\n",
    "paths = sorted(glob.glob(r'/content/drive/MyDrive/NLP/NLP Interim Dataset/NLP/*.wav'))\n",
    "q_data = list(map(test_gen.path_to_mel, paths))\n",
    "\n",
    "q_data = tf.stack(q_data)\n",
    "\n",
    "preds = own.predict(q_data)\n",
    "preds = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMiSafBkOTfp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "q_df['paths'] = sorted(os.listdir(r'/content/drive/MyDrive/NLP/NLP Interim Dataset/NLP/'))\n",
    "q_df['labels'] = list(map(\n",
    "    test_gen.int_to_label,\n",
    "    list(preds)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbFehkxqUGss",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "q_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kcxfIZE2UlkK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "q_df.to_csv(r'/content/drive/MyDrive/NLP/Zhihao nlp preds/qualifiers3.csv', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "zhihao_nlp_2022TIL_(ignore othernotebook).ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "38c7ce74dd526bc9e84fd0682f6c1ac8fcd6c4cb0e87d36fcf4e0e214217cc07"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}